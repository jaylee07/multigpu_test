{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most of the experiments are cited from \n",
    "- https://medium.com/daangn/pytorch-multi-gpu-%ED%95%99%EC%8A%B5-%EC%A0%9C%EB%8C%80%EB%A1%9C-%ED%95%98%EA%B8%B0-27270617936b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import OrderedDict\n",
    "import utils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_datadir = '/data/jehyuk/TEP/single_states/'\n",
    "trans_datadir = '/data/jehyuk/TEP/transient_processes/'\n",
    "attack_datadir = '/data/jehyuk/TEP/attacks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_datalist = sorted(os.listdir(single_datadir))\n",
    "trans_datalist = sorted(os.listdir(trans_datadir))\n",
    "attack_datalist = sorted(os.listdir(attack_datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_columns = ['Time', 'A Feed', 'D Feed', 'E Feed', 'A + C Feed', \n",
    "                 'Recycle flow', 'Reactor feed', 'Reactor pressure', 'Reactor level','Reactor temperature',\n",
    "                 'Purge rate', 'Seperator temperature', 'Seperator level', 'Seperator pressure', 'Seperator underflow',\n",
    "                 'Stripper level', 'Stripper pressure', 'Stripper underflow',  'Stripper temperature', 'Stripper Steam flow_meas',\n",
    "                 'Compressor work', 'Reactor cooling water temperature', 'Condensor cooling water temperature', 'Feed %A', 'Feed %B', \n",
    "                 'Feed %C', 'Feed %D', 'Feed %E', 'Feed %F', 'Purge %A', \n",
    "                 'Purge %B', 'Purge %C', 'Purge %D', 'Purge %E', 'Purge %F', \n",
    "                 'Purge %G', 'Purge %H', 'Product %D', 'Product %E', 'Product %F', \n",
    "                 'Product %G', 'Product %H', 'D feed flow', 'E feed flow', 'A feed flow', \n",
    "                 'C feed flow', 'Compressor recycle valve', 'Purge flow', 'Separator liquid flow', 'Stripper liquid product flow',\n",
    "                 'Stripper Steam flow_mv', 'Reactor cooling water flow', 'Condenser cooling water flow', 'Reactor Agitator speed', 'is_mv_attack',\n",
    "                 'is_meas_attack', 'is_sp_attack', 'state', 'product_rate', 'hourly_cost']\n",
    "\n",
    "measured_columns = ['A Feed', 'D Feed', 'E Feed', 'A + C Feed', \n",
    "                    'Recycle flow', 'Reactor feed', 'Reactor pressure', 'Reactor level','Reactor temperature',\n",
    "                    'Purge rate', 'Seperator temperature', 'Seperator level', 'Seperator pressure', 'Seperator underflow',\n",
    "                    'Stripper level', 'Stripper pressure', 'Stripper underflow',  'Stripper temperature', 'Stripper Steam flow_meas',\n",
    "                    'Compressor work', 'Reactor cooling water temperature', 'Condensor cooling water temperature', \n",
    "                    'Feed %A', 'Feed %B', 'Feed %C', 'Feed %D', 'Feed %E', 'Feed %F',\n",
    "                    'Purge %A', 'Purge %B', 'Purge %C', 'Purge %D', 'Purge %E', 'Purge %F', 'Purge %G', 'Purge %H',\n",
    "                    'Product %D', 'Product %E', 'Product %F', 'Product %G', 'Product %H']\n",
    "\n",
    "# manipulated vars == control vars\n",
    "manipulated_columns = ['D feed flow', 'E feed flow', 'A feed flow', 'C feed flow', \n",
    "                       'Compressor recycle valve', 'Purge flow', 'Separator liquid flow', 'Stripper liquid product flow',\n",
    "                       'Stripper Steam flow_mv', 'Reactor cooling water flow', 'Condenser cooling water flow', 'Reactor Agitator speed']\n",
    "\n",
    "attack_columns = ['is_mv_attack', 'is_meas_attack', 'is_sp_attack']\n",
    "general_columns = ['Time', 'state', 'product_rate', 'hourly_cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mode0,1,2,3,4,5,6: Different data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_mode0_datalist = sorted([x for x in single_datalist if 'mode_0' in x])\n",
    "tst_mode0_type21_datalist = sorted([x for x in attack_datalist if 'mode_0_type_21' in x])\n",
    "tst_mode0_type22_datalist = sorted([x for x in attack_datalist if 'mode_0_type_22' in x])\n",
    "tst_mode0_type23_datalist = sorted([x for x in attack_datalist if 'mode_0_type_23' in x])\n",
    "tst_mode0_type24_datalist = sorted([x for x in attack_datalist if 'mode_0_type_24' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_ex1 = pd.read_csv(os.path.join(single_datadir, trn_mode0_datalist[0]), names = total_columns)\n",
    "# trn_ex2 = pd.read_csv(os.path.join(single_datadir, trn_mode0_datalist[2]), names = total_columns)\n",
    "# tst_ex1 = pd.read_csv(os.path.join(attack_datadir, tst_mode0_type21_datalist[0]), names = total_columns)\n",
    "# tst_ex2 = pd.read_csv(os.path.join(attack_datadir, tst_mode0_type21_datalist[2]), names = total_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(trn_ex1['Reactor temperature'][71250:71500])\n",
    "# plt.plot(trn_ex2['Reactor temperature'][71250:71500])\n",
    "# plt.plot(tst_ex1['Reactor temperature'][71250:71500])\n",
    "# plt.plot(tst_ex2['Reactor temperature'][71250:71500])\n",
    "# # plt.plot(110+tst_ex['is_meas_attack'][71250:71500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statdict(df, used_cols=measured_columns+manipulated_columns):\n",
    "    stat_dict = dict()\n",
    "    for col in used_cols:\n",
    "        stat_dict[col] = dict()\n",
    "        stat_dict[col]['mean'] = df[col].mean()\n",
    "        stat_dict[col]['std'] = df[col].std()\n",
    "        stat_dict[col]['min'] = df[col].min()\n",
    "        stat_dict[col]['max'] = df[col].max()\n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_bool_to_float(df, used_cols):\n",
    "    df = df[used_cols]\n",
    "#     df *= 1\n",
    "    df = df.astype(float)\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, stat_dict, used_cols, normalize_method = 'none'):\n",
    "    eps = 1e-7\n",
    "    df_new = copy.copy(df[used_cols])\n",
    "    for col in used_cols:\n",
    "        stats = stat_dict[col]\n",
    "        if normalize_method == 'none':\n",
    "            continue\n",
    "        elif normalize_method == 'z':\n",
    "            df_new[col] = (df[col] - stats['mean']) / (stats['std'] + eps)\n",
    "        elif normalize_method == 'minmax':\n",
    "            df_new[col] = (df[col] - stats['min']) / (stats['max'] - stats['min'] + eps)\n",
    "    return df_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_twlist(tw=500, datadir=single_datadir, datalist=trn_mode0_datalist):\n",
    "    total_twlist = []\n",
    "    total_datalist = []\n",
    "    for i, fname in enumerate(datalist):\n",
    "        start = time.time()\n",
    "        data = pd.read_csv(os.path.join(datadir, fname), names=total_columns)\n",
    "   \n",
    "        twlist = [data[j-tw: j] for j in range(tw, data.shape[0])]\n",
    "        total_datalist.append(data)\n",
    "        total_twlist.extend(twlist)\n",
    "        print('{}/{} fname: {}, len(twlist): {}, elapsed_time: {:.2f}s'.format(i+1, len(datalist), fname[:-4], len(twlist), time.time()-start))\n",
    "    df_total = pd.concat([x for x in total_datalist], axis=0)\n",
    "\n",
    "    return total_twlist, df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_twlist, df_total = make_twlist(datadir=single_datadir,datalist=trn_mode0_datalist)\n",
    "stat_dict = get_statdict(df_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_twlist, _ = make_twlist(datadir=attack_datadir, datalist=tst_mode0_type21_datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_op = transforms.Compose([dataset.Preprocessing(used_cols = measured_columns + manipulated_columns, \n",
    "                                                        stat_dict = stat_dict, normalize_method='minmax'),\n",
    "                                   dataset.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dset = dataset.TWDataset(trn_twlist, transform=transform_op)\n",
    "tst_dset = dataset.TWDataset(tst_twlist, transform=transform_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_list = []\n",
    "# for i, df in tqdm.tqdm_notebook(enumerate(tst_twlist), total=len(tst_twlist)):\n",
    "#     np_df = df.values\n",
    "#     np_list.append(np_df)\n",
    "#     if (i+1) % 10000 == 0:\n",
    "#         time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderConv1d(nn.Module):\n",
    "    def __init__(self, tw, n_vars, kernels, strides, paddings, n_ch,\n",
    "                 actfn_name='relu', use_fc=False, fc_size=20):\n",
    "        super(EncoderConv1d, self).__init__()\n",
    "        self.tw = tw\n",
    "        self.n_vars = n_vars\n",
    "        self.kernels = kernels\n",
    "        self.strides = strides\n",
    "        self.paddings = paddings\n",
    "        self.use_fc = use_fc\n",
    "        self.n_ch =n_ch\n",
    "\n",
    "        k, s, p = kernels, strides, paddings\n",
    "        length = tw\n",
    "        act_fn = utils.get_actfn(actfn_name)\n",
    "\n",
    "        layers = OrderedDict()\n",
    "        in_ch, out_ch = n_vars, self.n_ch\n",
    "        for i in range(len(k)-1):\n",
    "            layers[f'conv{i+1}'] = nn.Conv1d(in_ch, out_ch, k[i], s[i], p[i], bias=False)\n",
    "            layers[f'bn{i+1}'] = nn.BatchNorm1d(num_features=out_ch)\n",
    "            layers[f'act{i+1}'] = act_fn\n",
    "            length = utils.conv1d_output_size(length, k[i], s[i], p[i])\n",
    "            in_ch, out_ch = out_ch, out_ch*2\n",
    "        i += 1\n",
    "        layers[f'conv{i+1}'] = nn.Conv1d(in_ch, out_ch, k[i], s[i], p[i], bias=True) # No batchnorm -> Bias!\n",
    "        length = utils.conv1d_output_size(length, k[i], s[i], p[i])\n",
    "        self.layers = nn.Sequential(layers)\n",
    "        if self.use_fc:\n",
    "            self.fc = nn.Linear(length * out_ch, fc_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        if self.use_fc:\n",
    "            out = torch.flatten(out, start_dim=1)\n",
    "            out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderConv1d(nn.Module):\n",
    "    def __init__(self, tw, n_vars, kernels, strides, paddings, n_ch,\n",
    "                 embed_length, actfn_name='relu', outactfn_name='sigmoid', use_fc=False, fc_size=20):\n",
    "        super(DecoderConv1d, self).__init__()\n",
    "        self.tw = tw\n",
    "        self.n_vars =n_vars\n",
    "        self.kernels = [x for x in reversed(kernels)]\n",
    "        self.strides = [x for x in reversed(strides)]\n",
    "        self.paddings = [x for x in reversed(paddings)]\n",
    "        self.n_ch = n_ch\n",
    "        self.embed_length = embed_length\n",
    "        self.use_fc = use_fc\n",
    "        self.fc_size = fc_size\n",
    "\n",
    "        k, s, p = self.kernels, self.strides, self.paddings\n",
    "\n",
    "        in_ch = self.n_ch * (2**(len(k)-1))\n",
    "        out_ch = int(in_ch / 2)\n",
    "        if self.use_fc:\n",
    "            self.fc = nn.Linear(self.fc_size, embed_length * in_ch)\n",
    "        length = embed_length\n",
    "        act_fn = utils.get_actfn(actfn_name)\n",
    "        outact_fn = utils.get_actfn(outactfn_name)\n",
    "        layers = OrderedDict()\n",
    "        for i in range(len(k)-1):\n",
    "            layers[f'convtr{i+1}'] = nn.ConvTranspose1d(in_ch, out_ch, k[i], s[i], p[i], bias=False)\n",
    "            layers[f'bn{i+1}'] = nn.BatchNorm1d(num_features=out_ch)\n",
    "            layers[f'act{i+1}'] = act_fn\n",
    "            length = utils.convtr1d_output_size(length, k[i], s[i], p[i])\n",
    "            in_ch, out_ch = out_ch, int(out_ch/2)\n",
    "        i += 1\n",
    "        layers[f'convtr{i+1}'] = nn.ConvTranspose1d(in_ch, n_vars, k[i], s[i], p[i], bias=True)\n",
    "        # length = utils.convtr1d_output_size(length, k[i], s[i], p[i])\n",
    "        self.layers = nn.Sequential(layers)\n",
    "        self.outact_fn = outact_fn\n",
    "        \n",
    "    def forward(self, z):\n",
    "        if self.use_fc:\n",
    "            z = self.fc(z)\n",
    "            out_ch = self.n_ch * (2**(len(self.kernels)-1))\n",
    "            z = z.view(-1, out_ch, self.embed_length)\n",
    "        out = self.layers(z)\n",
    "        if self.outact_fn is not None:\n",
    "            out = self.outact_fn(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = EncoderConv1d(tw=500, n_vars = len(measured_columns+manipulated_columns), \n",
    "#                     kernels=[5,5,5,5], strides=[1,1,1,1], paddings=[0,0,0,0], n_ch=64)\n",
    "# dec = DecoderConv1d(tw=500, n_vars=len(measured_columns+manipulated_columns),\n",
    "#                     kernels=[5,5,5,5], strides=[1,1,1,1], paddings=[0,0,0,0], n_ch=64,\n",
    "#                     embed_length=5, actfn_name='relu', outactfn_name='sigmoid', use_fc=False, fc_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(loader):\n",
    "#     batch['x'] = torch.transpose(batch['x'], 1, 2)\n",
    "#     batch['general'] = torch.transpose(batch['general'], 1, 2)\n",
    "#     batch['attack'] = torch.transpose(batch['attack'], 1, 2)\n",
    "#     if i ==0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = enc(batch['x'])\n",
    "# x_hat = dec(z)\n",
    "# print(z.size(), batch['x'].size(), x_hat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    def __init__(self):\n",
    "        self.trn_datadir = '/data/jehyuk/TEP/single_states/'\n",
    "        self.tst_datadir = '/data/jehyuk/TEP/attacks/'\n",
    "        self.mode = 0\n",
    "        self.tw = 500\n",
    "        self.k = [5,5,5,5]\n",
    "        self.s = [1,1,1,1]\n",
    "        self.p = [0,0,0,0]\n",
    "        self.n_ch = 128\n",
    "        self.actfn_name='relu'\n",
    "        self.outactfn_name='sigmoid'\n",
    "        self.use_fc=False\n",
    "        self.fc_size = 20\n",
    "        self.normalize = 'minmax'\n",
    "        self.lr = 0.0002\n",
    "        self.n_workers = 5\n",
    "        self.device_num = 0\n",
    "        self.whole_devices = [0,1,2,3]\n",
    "        self.weight_decay = 0.01\n",
    "        self.n_epoch = 1\n",
    "        self.trn_batch_size = 1024\n",
    "        self.tst_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE(nn.Module):\n",
    "    def __init__(self, tw, used_cols, k, s, p, n_ch, use_fc=False, fc_size=20, \n",
    "                 actfn_name='relu', outactfn_name='sigmoid'):\n",
    "        \"\"\"\n",
    "        :param tw: time window size\n",
    "        :param used_cols: column list which is used in modeling\n",
    "        :param k: kernel size list\n",
    "        :param s: stride size list\n",
    "        :param p: padding size list\n",
    "        :param n_ch: channel bunch\n",
    "        :param actfn_name: activation function in hidden layer. default='relu'\n",
    "        :param outactfn_name: activation function in output layer. default='sigmoid'\n",
    "        \"\"\"\n",
    "        super(ConvAE, self).__init__()\n",
    "        self.tw = tw\n",
    "        self.used_cols = used_cols\n",
    "        self.k = k\n",
    "        self.s = s\n",
    "        self.p = p\n",
    "        self.n_ch = n_ch\n",
    "        embed_len = tw\n",
    "        for i in range(len(k)):\n",
    "            embed_len = utils.conv1d_output_size(embed_len, k[i], s[i], p[i])\n",
    "        self.enc = EncoderConv1d(tw, len(used_cols), k, s, p, n_ch, actfn_name, use_fc, fc_size)\n",
    "        self.dec = DecoderConv1d(tw, len(used_cols), k, s, p, n_ch, embed_len, actfn_name, outactfn_name, use_fc, fc_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.enc(x)\n",
    "        x_hat = self.dec(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f'cuda:{args.device_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvAE(args.tw, measured_columns+manipulated_columns, args.k, args.s, args.p, args.n_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Use DataParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델을 각 GPU에 복사해서 할당 (replicate)\n",
    "- 매 iteration마다 batch를 GPU수만큼 분배 (scatter)\n",
    "- 각 GPU에서 forward를 진행 (parallel_apply)\n",
    "- 각 GPU에서 모델이 출력을 내보내면 이 출력들을 하나의 GPU로 collect (gather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_loader = DataLoader(trn_dset, batch_size = args.trn_batch_size, num_workers=5, shuffle=True)\n",
    "# tst_loader = DataLoader(tst_dset, batch_size = args.tst_batch_size, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AETrainer1:\n",
    "#     def __init__(self, model, lr, weight_decay, device, whole_devices, check_every=10):\n",
    "#         \"\"\"\n",
    "#         :param model: AE model to train\n",
    "#         :param trn_loader: train data loader\n",
    "#         :param tst_loader: test data loader\n",
    "#         :param lr: learning rate\n",
    "#         :param weight_decay: weight decay\n",
    "#         :param device: torch.device('cuda:{}') where the main model is positioned\n",
    "#         :param whole_device: list of cuda numbers where the parallel operation is done\n",
    "#         :param check_every: logging frequency\n",
    "#         \"\"\"\n",
    "#         self.model = model.to(device)\n",
    "#         self.lr = lr\n",
    "#         self.weight_decay = weight_decay\n",
    "#         self.device = device\n",
    "#         self.whole_devices = whole_devices\n",
    "#         self.check_every = check_every\n",
    "#         if device.type == 'cuda' and torch.cuda.device_count()>1 and len(whole_devices) > 1:\n",
    "#             print(\"Using {} gpus for training AE\".format(len(whole_devices)))\n",
    "#             self.model = nn.DataParallel(self.model, device_ids=whole_devices)\n",
    "#         self.optim = optim.Adam(self.model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "#         self.criterion = nn.MSELoss(reduction='sum')\n",
    "#         self.check_every = check_every\n",
    "        \n",
    "#     def partial_fit(self, data_loader, epoch, train=True):\n",
    "#         \"\"\"\n",
    "#         :param data_loader: torch.utils.data.DataLoader for iteration\n",
    "#         :param train: boolean value whether it is train or test\n",
    "#         \"\"\"\n",
    "#         str_code = 'train' if train else 'test'\n",
    "#         data_iter = tqdm.tqdm_notebook(enumerate(data_loader), \n",
    "#                                        desc='epoch_{}:{}'.format(str_code, epoch), \n",
    "#                                        total=len(data_loader))\n",
    "#         avg_loss = 0\n",
    "#         for iter_num, batch in data_iter:\n",
    "#             if train:\n",
    "#                 self.model.train()\n",
    "#             else:\n",
    "#                 self.model.eval()\n",
    "#             self.optim.zero_grad()\n",
    "#             x=torch.transpose(batch['x'], 1, 2).to(self.device)\n",
    "#             general = batch['general'].to(self.device)\n",
    "#             attack = batch['attack'].to(self.device)\n",
    "#             x_hat = self.model(x)\n",
    "#             loss = self.criterion(x_hat, x)\n",
    "#             avg_loss += loss.item()\n",
    "#             loss.backward()\n",
    "#             self.optim.step()\n",
    "#             post_fix = {\n",
    "#                 \"epoch\": epoch, \n",
    "#                 \"iter\": iter_num+1, \n",
    "#                 \"avg_loss\": avg_loss / (data_loader.batch_size*(iter_num+1)),\n",
    "#                 \"batch_loss\": loss.item() / data_loader.batch_size\n",
    "#             }\n",
    "#             if (iter_num+1) % self.check_every == 0:\n",
    "#                 data_iter.write(str(post_fix))\n",
    "    \n",
    "#     def train(self, data_loader, n_epoch, train=True):\n",
    "#         for epoch in tqdm.tqdm_notebook(range(1, n_epoch+1)):\n",
    "#             self.partial_fit(data_loader, epoch, train)\n",
    "            \n",
    "#     def test(self, data_loader, epoch=0, train=False):\n",
    "#         self.partial_fit(data_loader, epoch, train)\n",
    "    \n",
    "#     def save_model(self, save_dir):\n",
    "#         if device.type == 'cuda' and torch.cuda.device_count()>1 and len(self.whole_devices)>1:\n",
    "#             torch.save(self.model.module.encoder.state_dict(), os.path.join(save_dir, 'encoder.pkl'))\n",
    "#             torch.save(self.model.module.decoder.state_dict(), os.path.join(save_dir, 'decoder.pkl'))\n",
    "#         else:\n",
    "#             torch.save(self.model.encoder.state_dict(), os.path.join(save_dir, 'encoder.pkl'))\n",
    "#             torch.save(self.model.decoder.state_dict(), os.path.join(save_dir, 'decoder.pkl'))\n",
    "       \n",
    "#     def load_model(self, save_dir):\n",
    "#         if device.type == 'cuda' and torch.cuda.device_count()>1 and len(self.whole_devices)>1:\n",
    "#             self.model.module.encoder.load_state_dict(torch.load(os.path.join(save_dir, 'encoder.pkl')))\n",
    "#             self.model.module.decoder.load_state_dict(torch.load(os.path.join(save_dir, 'decoder.pkl')))\n",
    "#         else:\n",
    "#             self.model.encoder.load_state_dict(torch.load(os.path.join(save_dir, 'encoder.pkl')))\n",
    "#             self.model.decoder.load_state_dict(torch.load(os.path.join(save_dir, 'decoder.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = AETrainer1(model, args.lr, args.weight_decay, device, args.whole_devices, check_every=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer.train(trn_loader, args.n_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Custom DataParallel 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pytorch의 nn.DataParallel을 사용하면 메모리 불균형이 생긴다.\n",
    "    - 이는 위에서 언급한 gather 프로세스 때문에 이런 현상이 발생한다.\n",
    "    - 왜 그래야 할까?\n",
    "        - 모델은 DataParallel을 통해 병렬 연산이 가능하게 했지만, loss function이 그대로\n",
    "        - 이러한 이유로 하나의 GPU로 출력값을 모아서 loss를 계산함\n",
    "\n",
    "\n",
    "- Loss function도 병렬로 연산하도록 만들면 메모리 불균형 문제를 해결하는 것이 가능\n",
    "- How?\n",
    "    - Pytorch에서는 loss function도 하나의 모듈 --> loss function을 각 GPU에 replicate(*)\n",
    "    - 정답 tensor를 각 GPU로 scatter\n",
    "    - loss를 계산하기 위한 모델에서의 출력값, loss function, 정답 tensor 모두 각 GPU에 존재 --> 각 GPU에서 loss 계산 가능 --> loss backward\n",
    "    \n",
    "    \n",
    "- How to replicate the loss function module?\n",
    "    - target을 각 GPU로 scatter하고, 각 GPU에 replicate된 모듈에서 계산을 한다.\n",
    "    - 계산된 output과 Reduce.apply를 통해 각 GPU에서 backward연산을 하도록 한다.\n",
    "    \n",
    "    \n",
    "- Custom DataParallel class인 DataParallelModel을 사용한다.\n",
    "    - nn.DataParallel은 기본적으로 하나의 GPU로 출력을 모은다.\n",
    "    - Pytorch-Encoding package에서 parallel.py파일을 가져와서 학습코드에서 import하도록 하면 된다.\n",
    "        - Source code: https://github.com/zhanghang1989/PyTorch-Encoding/blob/master/encoding/parallel.py\n",
    "        - Issues: https://github.com/zhanghang1989/PyTorch-Encoding/issues/54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AETrainer2:\n",
    "    def __init__(self, model, lr, weight_decay, device, whole_devices, check_every=10):\n",
    "        \"\"\"\n",
    "        :param model: AE model to train\n",
    "        :param trn_loader: train data loader\n",
    "        :param tst_loader: test data loader\n",
    "        :param lr: learning rate\n",
    "        :param weight_decay: weight decay\n",
    "        :param device: torch.device('cuda:{}') where the main model is positioned\n",
    "        :param whole_device: list of cuda numbers where the parallel operation is done\n",
    "        :param check_every: logging frequency\n",
    "        \"\"\"\n",
    "        torch.cuda.empty_cache()\n",
    "        self.model = model.to(device)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.device = device\n",
    "        self.whole_devices = whole_devices\n",
    "        self.check_every = check_every\n",
    "        self.criterion = nn.MSELoss(reduction='sum')\n",
    "        self.optim = optim.Adam(self.model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "        if device.type == 'cuda' and torch.cuda.device_count()>1 and len(whole_devices) > 1:\n",
    "            print(\"Using {} gpus for training AE\".format(len(whole_devices)))\n",
    "            self.model = parallel.DataParallelModel(self.model).to(device)\n",
    "#             nn.DataParallel(self.model, device_ids=whole_devices)\n",
    "            self.criterion = parallel.DataParallelCriterion(self.criterion).to(device)\n",
    "        self.check_every = check_every\n",
    "        \n",
    "    def partial_fit(self, data_loader, epoch, train=True):\n",
    "        \"\"\"\n",
    "        :param data_loader: torch.utils.data.DataLoader for iteration\n",
    "        :param train: boolean value whether it is train or test\n",
    "        \"\"\"\n",
    "        str_code = 'train' if train else 'test'\n",
    "        data_iter = tqdm.tqdm_notebook(enumerate(data_loader), \n",
    "                                       desc='epoch_{}:{}'.format(str_code, epoch), \n",
    "                                       total=min(len(data_loader), 100))\n",
    "        avg_loss = 0\n",
    "        for iter_num, batch in data_iter:\n",
    "            if train:\n",
    "                self.model.train()\n",
    "            else:\n",
    "                self.model.eval()\n",
    "            self.optim.zero_grad()\n",
    "            x=torch.transpose(batch['x'], 1, 2).to(self.device)\n",
    "            general = batch['general'].to(self.device)\n",
    "            attack = batch['attack'].to(self.device)\n",
    "            x_hat = self.model(x)\n",
    "            loss = self.criterion(x_hat, x)\n",
    "            avg_loss += loss.item()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            post_fix = {\n",
    "                \"epoch\": epoch, \n",
    "                \"iter\": iter_num+1, \n",
    "                \"avg_loss\": avg_loss / (data_loader.batch_size*(iter_num+1)),\n",
    "                \"batch_loss\": loss.item() / data_loader.batch_size\n",
    "            }\n",
    "            if (iter_num+1) % self.check_every == 0:\n",
    "                data_iter.write(str(post_fix))\n",
    "                \n",
    "            if (iter_num+1) == 50:\n",
    "                break\n",
    "\n",
    "    \n",
    "    def train(self, data_loader, n_epoch, train=True):\n",
    "        for epoch in tqdm.tqdm_notebook(range(1, n_epoch+1)):\n",
    "            self.partial_fit(data_loader, epoch, train)\n",
    "            \n",
    "    def test(self, data_loader, epoch=0, train=False):\n",
    "        self.partial_fit(data_loader, epoch, train)\n",
    "    \n",
    "    def save_model(self, save_dir):\n",
    "        if device.type == 'cuda' and torch.cuda.device_count()>1 and len(self.whole_devices)>1:\n",
    "            torch.save(self.model.module.encoder.state_dict(), os.path.join(save_dir, 'encoder.pkl'))\n",
    "            torch.save(self.model.module.decoder.state_dict(), os.path.join(save_dir, 'decoder.pkl'))\n",
    "        else:\n",
    "            torch.save(self.model.encoder.state_dict(), os.path.join(save_dir, 'encoder.pkl'))\n",
    "            torch.save(self.model.decoder.state_dict(), os.path.join(save_dir, 'decoder.pkl'))\n",
    "       \n",
    "    def load_model(self, save_dir):\n",
    "        if device.type == 'cuda' and torch.cuda.device_count()>1 and len(self.whole_devices)>1:\n",
    "            self.model.module.encoder.load_state_dict(torch.load(os.path.join(save_dir, 'encoder.pkl')))\n",
    "            self.model.module.decoder.load_state_dict(torch.load(os.path.join(save_dir, 'decoder.pkl')))\n",
    "        else:\n",
    "            self.model.encoder.load_state_dict(torch.load(os.path.join(save_dir, 'encoder.pkl')))\n",
    "            self.model.decoder.load_state_dict(torch.load(os.path.join(save_dir, 'decoder.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = AETrainer2(model, args.lr, args.weight_decay, device, args.whole_devices, check_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_loader = DataLoader(trn_dset, batch_size = args.trn_batch_size, num_workers=5, shuffle=True)\n",
    "# tst_loader = DataLoader(tst_dset, batch_size = args.tst_batch_size, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train(trn_loader, args.n_epoch, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pytorch에서 Distributed Package 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 코드: https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "- 분산 학습을 사용해서 Multi-GPU 학습 하기(예제 코드를 기반으로)\n",
    "    - main.py를 실행하면, line 109의 mp.spawn(main_worker, ...)가 실행됨\n",
    "        - main_worker에서는 4개의 GPU를 한개의 node로 간주하고, world_size를 결정(line 106)\n",
    "        - mp.spawn은 4개의 GPU에서 따로 따로 main_worker을 multi processing으로 실행(line 109)\n",
    "        \n",
    "    - dist.init_process_group (line 129)\n",
    "        - 각 GPU마다 분산학습을 위한 초기화\n",
    "        - Pytorch의 document에서는 multi-GPU학습시, backend로 nccl을 사용하라고 함\n",
    "        - init_method에서 FREEPORT에 사용 가능한 port를 적으면 됨\n",
    "        - 초기화를 실행하고 나면, 분산학습이 가능해짐\n",
    "        \n",
    "    - torch.nn.parallel.DistributedDataParallel(DDP) (line 151, 156)\n",
    "        - DDP는 module level에서 data parallelism을 실행함\n",
    "        - torch.distributed 패키지 내의 communication collectives를 사용하여, \n",
    "          gradient, params, buffers를 synchronize한다.\n",
    "        - Within process, across process가 둘 다 가능하다.\n",
    "            - Within: nn.DataParallel과 유사\n",
    "            - Across: DDP는 필요한 params들에 대해, forward에서 synchronization하고, backward에서 grad syncrhonization\n",
    "            \n",
    "    - DistributedSampler (line 210)\n",
    "        - dset을 DistributedSampler로 감싸주고, DataLoader에서 sampler에 인자로 넣어줌\n",
    "        - DDP와 함께 사용해야 함\n",
    "        - 작동 원리\n",
    "            - 각 sampler는 전체 데이터를 GPU 갯수로 나눈 부분 데이터에서만 데이터를 샘플링\n",
    "            - 부분데이터를 만들기 위해 전체 dset의 idx list를 무작위로 섞고, \n",
    "              해당 idx list를 쪼개서 GPU sampler에 할당\n",
    "            - Epoch마다 idx list가 계속 달라지므로, train_sampler.set_epoch(epoch)를 매 epoch마다 학습전에 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does not work in this server!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data.distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    def __init__(self):\n",
    "        self.trn_datadir = '/data/jehyuk/TEP/single_states/'\n",
    "        self.tst_datadir = '/data/jehyuk/TEP/attacks/'\n",
    "        self.mode = 0\n",
    "        self.tw = 500\n",
    "        self.k = [5,5,5,5]\n",
    "        self.s = [1,1,1,1]\n",
    "        self.p = [0,0,0,0]\n",
    "        self.n_ch = 128\n",
    "        self.actfn_name='relu'\n",
    "        self.outactfn_name='sigmoid'\n",
    "        self.use_fc=False\n",
    "        self.fc_size = 20\n",
    "        self.normalize = 'minmax'\n",
    "        self.lr = 0.0002\n",
    "        self.n_workers = 5\n",
    "        self.device_num = 0\n",
    "        self.whole_devices = [0,1,2,3]\n",
    "        self.weight_decay = 0.01\n",
    "        self.n_epoch = 1\n",
    "        self.trn_batch_size = 1024\n",
    "        self.tst_batch_size = 128\n",
    "        self.dist_url = 'tcp://147.46.178.58:54321'\n",
    "        self.dist_backend = 'nccl'\n",
    "        self.world_size = 1\n",
    "        self.distributed = True\n",
    "        self.rank = 0\n",
    "        self.num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvAE(args.tw, measured_columns+manipulated_columns, args.k, args.s, args.p, args.n_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f'cuda:{args.device_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_op = transforms.Compose([dataset.Preprocessing(used_cols = measured_columns + manipulated_columns, \n",
    "                                                         stat_dict = stat_dict, normalize_method='minmax'),\n",
    "                                   dataset.ToTensor()])\n",
    "trn_dset = dataset.TWDataset(trn_twlist, transform=transform_op)\n",
    "tst_dset = dataset.TWDataset(tst_twlist, transform=transform_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AETrainer3:\n",
    "    def __init__(self, model, args):\n",
    "#         torch.cuda.empty_cache()\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "        self.ngpus_per_node = len(args.whole_devices)\n",
    "        self.world_size = self.ngpus_per_node * self.args.world_size\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.opt = optim.Adam(self.model.parameters(), lr = args.lr, weight_decay = args.weight_decay)\n",
    "        \n",
    "    def train_per_worker(device_num, trn_dset, ngpus_per_node, args):\n",
    "        args.device_num = device_num\n",
    "        print(1)\n",
    "        device = torch.device(f'cuda:{args.device_num}')\n",
    "        print(2)\n",
    "        ngpus_per_node = len(args.whole_deivces)\n",
    "        print(3)\n",
    "        args.rank = args.rank * ngpus_per_node + args.device_num\n",
    "        print(4)\n",
    "        dist.init_process_group(backend=args.dist_bacekend, init_method=args.dist_url, \n",
    "                                world_size=args.world_size, rank=args.rank)\n",
    "        print(5)\n",
    "        self.model.to(device)\n",
    "        print(6)\n",
    "        args.trn_batch_size = int(args.trn_batch_size / ngpus_per_node)\n",
    "        args.tst_batch_size = int(args.tst_batch_size / ngpus_per_node)\n",
    "        print(7)\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model).to(device)\n",
    "        print(8)\n",
    "        n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(9)\n",
    "        print('# of params of model is : {}'.format(n_params))\n",
    "        \n",
    "        print('>>Preparing Data...')\n",
    "        \n",
    "        trn_sampler = torch.utils.data.distributed.DistributedSampler(trn_dset)\n",
    "        trn_loader = DataLoader(trn_dset, batch_size = args.batch_size, \n",
    "                                shuffle=(trn_sampler is None), \n",
    "                                num_workers = args.num_workers, \n",
    "                                sampler = trn_sampler)\n",
    "        \n",
    "        \n",
    "        for epoch in range(1, args.n_epoch+1):\n",
    "            trn_sampler.set_epoch(epoch)\n",
    "            self.train_epoch(trn_loader, train=True, device=device)\n",
    "        \n",
    "    def train_epoch(self, data_loader, train, device):\n",
    "        str_code = 'train' if train else 'test'\n",
    "        data_iter = tqdm.tqdm_notebook(enumerate(data_loader), \n",
    "                                       desc='epoch_{}:{}'.format(str_code, epoch), \n",
    "                                       total = min(len(data_loader), 50))\n",
    "        avg_loss = 0\n",
    "        for iter_num, batch in data_iter:\n",
    "            if train:\n",
    "                self.model.train()\n",
    "            else:\n",
    "                self.model.eval()\n",
    "            self.optim.zero_grad()\n",
    "            x=torch.transpose(batch['x'], 1, 2).to(self.device)\n",
    "            general = batch['general'].to(self.device)\n",
    "            attack = batch['attack'].to(self.device)\n",
    "            x_hat = self.model(x)\n",
    "            loss = self.criterion(x_hat, x)\n",
    "            avg_loss += loss.item()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            post_fix = {\n",
    "                \"epoch\": epoch, \n",
    "                \"iter\": iter_num+1, \n",
    "                \"avg_loss\": avg_loss / (data_loader.batch_size*(iter_num+1)),\n",
    "                \"batch_loss\": loss.item() / data_loader.batch_size\n",
    "            }\n",
    "            if (iter_num+1) % self.check_every == 0:\n",
    "                data_iter.write(str(post_fix))\n",
    "                \n",
    "            if (iter_num+1) == 50:\n",
    "                break\n",
    "                \n",
    "    def train(self, trn_dset, train=True):\n",
    "        args = self.args\n",
    "        args.world_size = self.ngpus_per_node * self.args.world_size\n",
    "        ngpus_per_node = self.ngpus_per_node\n",
    "        print(0)\n",
    "        mp.spawn(self.train_per_worker, nprocs = ngpus_per_node, args=(trn_dset, ngpus_per_node, args))\n",
    "        \n",
    "            \n",
    "#     def test(self, data_loader, epoch=0, train=False):\n",
    "#         self.partial_fit(data_loader, epoch, train)\n",
    "    \n",
    "#     def save_model(self, save_dir):\n",
    "#         if device.type == 'cuda' and torch.cuda.device_count()>1 and len(self.whole_devices)>1:\n",
    "#             torch.save(self.model.module.encoder.state_dict(), os.path.join(save_dir, 'encoder.pkl'))\n",
    "#             torch.save(self.model.module.decoder.state_dict(), os.path.join(save_dir, 'decoder.pkl'))\n",
    "#         else:\n",
    "#             torch.save(self.model.encoder.state_dict(), os.path.join(save_dir, 'encoder.pkl'))\n",
    "#             torch.save(self.model.decoder.state_dict(), os.path.join(save_dir, 'decoder.pkl'))\n",
    "       \n",
    "#     def load_model(self, save_dir):\n",
    "#         if device.type == 'cuda' and torch.cuda.device_count()>1 and len(self.whole_devices)>1:\n",
    "#             self.model.module.encoder.load_state_dict(torch.load(os.path.join(save_dir, 'encoder.pkl')))\n",
    "#             self.model.module.decoder.load_state_dict(torch.load(os.path.join(save_dir, 'decoder.pkl')))\n",
    "#         else:\n",
    "#             self.model.encoder.load_state_dict(torch.load(os.path.join(save_dir, 'encoder.pkl')))\n",
    "#             self.model.decoder.load_state_dict(torch.load(os.path.join(save_dir, 'decoder.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = AETrainer3(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(trn_dset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
